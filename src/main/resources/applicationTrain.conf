# Kafka Parameters (Lectura desde Anubis df)
KAFKA_TOPIC_IN = "messages_in" #Topic para leer eventos del fichero con la informacion
KAFKA_DIRECTION_IN = "localhost:9092"
KAFKA_TOPIC_OUT = "messages_out" # Topic con los eventos procesados
KAFKA_DIRECTION_OUT = "localhost:9092"
KAFKA_DIR = "/home/alex/Documentos/tools/kafka_2.12-3.0.0" #Directorio local donde se encuentra Kafka

# Delta Parameters - Donde almacenaremos los recursos de Delta
# Trenes
TRAIN_DIR = "/tmp/delta/train"
TRAIN_DIR_TABLE = "/tmp/delta/train/table" # Directorio donde se almacena la delta table con toda la informacion desde el inicio
TRAIN_DIR_CHECKPOINT = "/tmp/delta/train/checkpoint" # Directorio donde se almacena los checkpoints de la delta table
PATH_EVENTS_FROM_TIMESTAMP = "/tmp/events_from_timestamp" # Directorio donde se almacena el .json con los eventos finitos desde el timestamp


# System parameters - Train - Columnas del stream inicial de Kafka
nombreSistema = "Train Events System"
nombreEvento = "EVENT_TYPE"
fechaEvento = "DATE_EVENT"
idEvento = "ID"
latitudEvento = "LAT"
longitudEvento = "LNG"
localizacionEvento = "LOCATION"

# Kafka Producers and consumers configuration (Python)
PYTHON_KAFKA_PRODUCER_TIMESTAMP = "/home/alex/Escritorio/TFM/streamer/kafka/TemporalStreamProducer.py" # Fichero que realiza el stream de los valores de la tabla a partir del timestamp seleccionado
NOMBRE_SISTEMA_TIMESTAMP = "Events from Timestamp"
KAFKA_TOPIC_TIMESTAMP_IN = "messages_from_timestamp_in" # Topic por el que se consumen el stream finito a partir de timestamp y el stream infinito
KAFKA_TOPIC_TIMESTAMP_OUT = "messages_from_timestamp_out" # Topic por el que se envia procesado los eventos a partir de un timestamp



